{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code used for generating temporal variation patterns from SuicideWatch on Reddit, as well as from a control set of posts from AskReddit, used in a study to understand posting patterns in terms of time. Here, the focus is on the time of day (in terms of hours).\n",
    "\n",
    "The underlying data is from https://redd.it/3mg812. To get access to the subsets used in this study, please contact us directly.\n",
    "\n",
    "The key steps for the analysis are the following:\n",
    "- We start with the published/downloaded archive and generate subsets for the analysis: SuicideWatch and AskReddit\n",
    "- We cast timestamp into datetime (we lost 0 posts as a result of this transformation, i.e. all have been casted to datetime properly)\n",
    "- We only keep posts and filter out comments by keeping messages that have no parent_id (NB: a message that has a valid parent_id means this message is a comment; this is documented in the Reddit pages)\n",
    "- We calculate the first Monday (firstMonday) and the last Sunday (lastSunday) from within our dataset. We filter out all posts that are before firstMonday or after lastSunday.\n",
    "- We then extract the hour of the day for each of the days of the week.\n",
    "\n",
    "Written by George Gkotsis, with input from Sumithra Velupillai, King's College London, 2016-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. suicidewatch\n",
    "# df = pd.read_pickle(\"../reddit/suicidewatch.pickle\")\n",
    "# fname = \"Suicidewatch-weekly\"\n",
    "\n",
    "# 2. suicidewatch - throwaway\n",
    "# df = pd.read_pickle(\"../reddit/suicidewatch.pickle\")\n",
    "# df = df[df['author'].str.contains('throw', case=False)]\n",
    "# fname = \"suicidewatch-throwaway-weekly\"\n",
    "\n",
    "# 3. AskReddit\n",
    "# df = pd.read_pickle(\"AskReddit_min.pickle\")\n",
    "# fname = \"AskReddit-weekly\"\n",
    "\n",
    "# 4. AskReddit - control\n",
    "df = pd.read_pickle(\"AskReddit_min.pickle\")\n",
    "authors = pd.read_pickle(\"../reddit/suicidewatch.pickle\")\n",
    "authors = authors[authors['parent_id'].astype(str)=='nan']\n",
    "authors = set(authors['author'].unique())\n",
    "authors.remove('[deleted]')\n",
    "df = df[df['author'].isin(authors)]\n",
    "fname = \"AskReddit-control-weekly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doDT(st):\n",
    "    import datetime\n",
    "    try:\n",
    "        return datetime.datetime.fromtimestamp(st)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def analyseDFWeek(df):\n",
    "    import datetime\n",
    "    if 'parent_id' in df.columns:\n",
    "        posts = df[df['parent_id'].astype(str)=='nan']\n",
    "    else:\n",
    "        posts = df\n",
    "    posts['created'] = posts['created'].apply(doDT)\n",
    "    a = len(posts)\n",
    "    posts = posts.dropna(subset=['created'])\n",
    "    b = len(posts)\n",
    "    print \"lost\", b-a, \"posts\"\n",
    "    posts = posts.set_index('created')        \n",
    "    firstMonday = posts[posts.index.dayofweek==0].index.min()\n",
    "    lastSunday = posts[posts.index.dayofweek==6].index.max()\n",
    "    posts = posts[posts.index>=firstMonday]\n",
    "    posts = posts[posts.index<=lastSunday]\n",
    "    d = firstMonday.date()\n",
    "    rs = pd.DataFrame()\n",
    "    while d<lastSunday.date():\n",
    "        tmp = posts[posts.index.date>=d]\n",
    "        end = d + datetime.timedelta(7)\n",
    "        tmp = posts[posts.index.date<end]\n",
    "        tmp['hour'] = tmp.index.hour\n",
    "        day = tmp.groupby(tmp.index.hour)['hour'].count()\n",
    "        day = pd.DataFrame(day)\n",
    "        cnt = day['hour'].sum()\n",
    "        day['pct'] = day['hour']/float(day['hour'].sum())\n",
    "        day = pd.DataFrame(day['pct']).transpose()\n",
    "        day['cnt'] = cnt\n",
    "        if cnt<200:\n",
    "            d = end\n",
    "            continue\n",
    "        rs = pd.concat([rs, day])\n",
    "        d = end\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lost 0 posts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rs = analyseDFWeek(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.to_excel(fname + \"-hourly.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
